{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36ec2c3a-ff60-4fd3-806b-8b8743ea441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35515cd9-23da-4904-9d81-6cf613cc8967",
   "metadata": {},
   "source": [
    "## Generate training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7a7a70-6ca0-4111-a796-09856414eff4",
   "metadata": {},
   "source": [
    "<img src=\"./assets/data_point_regression.png\" alt=\"neural_network\" width=\"300\">\n",
    "$\n",
    "f(X) =\n",
    "\\begin{cases} \n",
    "0 & \\text{if } X \\leq 0, \\\\\n",
    "X & \\text{if } 0 < X \\leq 1, \\\\\n",
    "2 - X & \\text{if } 1 < X \\leq 2, \\\\\n",
    "X - 2 & \\text{if } X > 2.\n",
    "\\end{cases}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0370f1ef-0be3-4a8f-9174-eeeb6ea3b593",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(0, 3, 50).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2df3c487-e90c-45ec-a4c7-d6b822fa7a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([0 ,\n",
    "0.06122449,\n",
    "0.12244898,\n",
    "0.18367347,\n",
    "0.24489796,\n",
    "0.30612245,\n",
    "0.36734694,\n",
    "0.42857143,\n",
    "0.48979592,\n",
    "0.55102041,\n",
    "0.6122449 ,\n",
    "0.67346939,\n",
    "0.73469388,\n",
    "0.79591837,\n",
    "0.85714286,\n",
    "0.91836735,\n",
    "0.97959184,\n",
    "1.04081633,\n",
    "1.10204082,\n",
    "1.16326531,\n",
    "1.2244898 ,\n",
    "1.28571429,\n",
    "1.34693878,\n",
    "1.40816327,\n",
    "1.46938776,\n",
    "1.53061224,\n",
    "1.59183673,\n",
    "1.65306122,\n",
    "1.71428571,\n",
    "1.7755102 ,\n",
    "1.83673469,\n",
    "1.89795918,\n",
    "1.95918367,\n",
    "2.02040816,\n",
    "2.08163265,\n",
    "2.14285714,\n",
    "2.20408163,\n",
    "2.26530612,\n",
    "2.32653061,\n",
    "2.3877551 ,\n",
    "2.44897959,\n",
    "2.51020408,\n",
    "2.57142857,\n",
    "2.63265306,\n",
    "2.69387755,\n",
    "2.75510204,\n",
    "2.81632653,\n",
    "2.87755102,\n",
    "2.93877551,\n",
    "3]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f045ef-4caf-41b5-82e1-41e4c9139cad",
   "metadata": {},
   "source": [
    "## Set Neural Network \n",
    "\n",
    "<img src=\"./assets/neural_network.png\" alt=\"neural_network\" width=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d194625b-846d-42a2-8217-081986de92ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize neural network parameters\n",
    "input_dim = 1\n",
    "hidden_dim = 3\n",
    "output_dim = 1\n",
    "\n",
    "np.random.seed(42)\n",
    "# Define hidden layer weights and biases\n",
    "weights_input_hidden = np.random.randn(input_dim, hidden_dim)\n",
    "bias_hidden = np.zeros((1, hidden_dim))           \n",
    "\n",
    "# Define output layer weights and biases\n",
    "weights_hidden_output = np.random.randn(hidden_dim, output_dim)\n",
    "bias_output = np.zeros((1, output_dim))\n",
    "\n",
    "# Define the activation function (ReLU)\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "# Define the loss function (MSE)\n",
    "def mse_loss(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred)**2)\n",
    "\n",
    "def mse_loss_derivative(y_true, y_pred):\n",
    "    return 2 * (y_pred - y_true) / y_true.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f989bb3-3f90-45bb-9f86-6bb9606eee79",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb16fd12-5d7d-4dc8-9064-f9bb400c1cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.4732\n",
      "Epoch 10, Loss: 0.0075\n",
      "Epoch 20, Loss: 0.0046\n",
      "Epoch 30, Loss: 0.0035\n",
      "Epoch 40, Loss: 0.0026\n",
      "Epoch 50, Loss: 0.0020\n",
      "Epoch 60, Loss: 0.0015\n",
      "Epoch 70, Loss: 0.0011\n",
      "Epoch 80, Loss: 0.0008\n",
      "Epoch 90, Loss: 0.0006\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    hidden_input = np.dot(X, weights_input_hidden) + bias_hidden  # Linear transformation\n",
    "    hidden_output = relu(hidden_input)                           # Apply ReLU\n",
    "    final_input = np.dot(hidden_output, weights_hidden_output) + bias_output  # Linear transformation\n",
    "    y_pred = final_input                                         # Output layer (no activation for regression)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = mse_loss(y, y_pred)\n",
    "\n",
    "    # Backpropagation\n",
    "    loss_gradient = mse_loss_derivative(y, y_pred)              # dL/dY^\n",
    "    grad_output_weights = np.dot(hidden_output.T, loss_gradient)  # Gradient for weights_hidden_output\n",
    "    grad_output_bias = np.sum(loss_gradient, axis=0, keepdims=True)  # Gradient for bias_output\n",
    "\n",
    "    hidden_gradient = np.dot(loss_gradient, weights_hidden_output.T) * relu_derivative(hidden_input)  # Backprop through ReLU\n",
    "    grad_input_weights = np.dot(X.T, hidden_gradient)           # Gradient for weights_input_hidden\n",
    "    grad_input_bias = np.sum(hidden_gradient, axis=0, keepdims=True)  # Gradient for bias_hidden\n",
    "\n",
    "    # Update weights and biases\n",
    "    weights_hidden_output -= learning_rate * grad_output_weights\n",
    "    bias_output -= learning_rate * grad_output_bias\n",
    "    weights_input_hidden -= learning_rate * grad_input_weights\n",
    "    bias_hidden -= learning_rate * grad_input_bias\n",
    "\n",
    "    # Print loss every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707968e2-c8b0-4ca5-b39b-27ffc8b69aa2",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "255bdc20-88c5-47ea-8f39-4661a5adb974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for input 1.0: 1.0198\n",
      "Prediction for input 0.5: 0.5310\n"
     ]
    }
   ],
   "source": [
    "test_input = np.array([[1],[0.5]])\n",
    "hidden_input = np.dot(test_input, weights_input_hidden) + bias_hidden\n",
    "hidden_output = relu(hidden_input)\n",
    "final_output = np.dot(hidden_output, weights_hidden_output) + bias_output\n",
    "\n",
    "for i in range(test_input.shape[0]): \n",
    "    print(f\"Prediction for input {test_input[i][0]}: {final_output[i][0]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
